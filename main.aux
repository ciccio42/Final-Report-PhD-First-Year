\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\BKM@entry[2]{}
\bibstyle{ieeetr}
\babel@aux{british}{}
\BKM@entry{id=1,dest={636861707465722A2E33},srcline={5}}{5C3337365C3337375C3030304F5C303030765C303030655C303030725C303030765C303030695C303030655C30303077}
\newlabel{chapter:overview}{{}{2}{Overview}{chapter*.3}{}}
\@writefile{toc}{\contentsline {chapter}{Overview}{2}{chapter*.3}\protected@file@percent }
\BKM@entry{id=2,dest={636861707465722E31},srcline={1}}{5C3337365C3337375C303030425C303030615C303030635C3030306B5C303030675C303030725C3030306F5C303030755C3030306E5C30303064}
\BKM@entry{id=3,dest={73656374696F6E2E312E31},srcline={1}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\citation{pepper}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Background}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:background}{{1}{3}{Background}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{3}{section.1.1}\protected@file@percent }
\newlabel{sec:intro}{{1.1}{3}{Introduction}{section.1.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:welding}{{1.1a}{3}{Robots involved in arc welding operation\relax }{figure.caption.4}{}}
\newlabel{sub@fig:welding}{{a}{3}{Robots involved in arc welding operation\relax }{figure.caption.4}{}}
\newlabel{fig:material_handling}{{1.1b}{3}{Robot involved in loading operation\relax }{figure.caption.4}{}}
\newlabel{sub@fig:material_handling}{{b}{3}{Robot involved in loading operation\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Industrial Robots: example of applications\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:industrial_robots_example}{{1.1}{3}{Industrial Robots: example of applications\relax }{figure.caption.4}{}}
\citation{panda}
\citation{kalashnikov2018qt_opt}
\citation{anne2021meta_learning_fast_adaptive}
\citation{jang2022bc_z}
\citation{hafner2011reinforcement_in_feedback_controll}
\citation{sutton2018reinforcement}
\citation{argall2009robot_learning_from_demonstration}
\citation{kaelbling1996reinforcement_survey}
\citation{osa2018algorithmic}
\citation{james2013introduction_to_sl}
\citation{cortes1995support}
\citation{kullback1951information}
\citation{levine202rl_tutorial}
\citation{levine202rl_tutorial}
\citation{levine202rl_tutorial}
\citation{hussein2017imitation_learning_survey}
\citation{torabi2019recent_advances_lfo}
\citation{codevilla2018end_to_end}
\citation{zhang2018deep_vr_teleoperation}
\citation{maeda2017probabilistic}
\newlabel{fig:onpolicy}{{1.2a}{5}{On-policy RL\relax }{figure.caption.5}{}}
\newlabel{sub@fig:onpolicy}{{a}{5}{On-policy RL\relax }{figure.caption.5}{}}
\newlabel{fig:offpolicy}{{1.2b}{5}{Off-policy RL\relax }{figure.caption.5}{}}
\newlabel{sub@fig:offpolicy}{{b}{5}{Off-policy RL\relax }{figure.caption.5}{}}
\newlabel{fig:offline}{{1.2c}{5}{Offline RL\relax }{figure.caption.5}{}}
\newlabel{sub@fig:offline}{{c}{5}{Offline RL\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Graphical Representation of Reinforcement Learning Methods \cite  {levine202rl_tutorial}\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:rl_methods}{{1.2}{5}{Graphical Representation of Reinforcement Learning Methods \cite {levine202rl_tutorial}\relax }{figure.caption.5}{}}
\BKM@entry{id=4,dest={73656374696F6E2E312E32},srcline={1}}{5C3337365C3337375C303030535C303030745C303030615C303030745C303030655C3030302D5C3030306F5C303030665C3030302D5C303030745C303030685C303030655C3030302D5C303030415C303030725C30303074}
\BKM@entry{id=5,dest={73756273656374696F6E2E312E322E31},srcline={1}}{5C3337365C3337375C303030505C303030725C3030306F5C303030625C3030306C5C303030655C3030306D5C3030305C3034305C303030445C303030655C303030665C303030695C3030306E5C303030695C303030745C303030695C3030306F5C3030306E}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Imitation Learning: Taxonomy and main components\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:il_methods}{{1.3}{6}{Imitation Learning: Taxonomy and main components\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}State-of-the-Art}{6}{section.1.2}\protected@file@percent }
\newlabel{sec:sota}{{1.2}{6}{State-of-the-Art}{section.1.2}{}}
\citation{fang2019survey}
\citation{osa2018algorithmic}
\citation{kroemer2021review_robot_learning}
\BKM@entry{id=6,dest={73756273656374696F6E2E312E322E32},srcline={1}}{5C3337365C3337375C303030535C3030306F5C303030755C303030725C303030635C303030655C3030305C3034305C3030306F5C303030665C3030305C3034305C303030445C303030655C3030306D5C3030306F5C3030306E5C303030735C303030745C303030725C303030615C303030745C303030695C3030306F5C3030306E}
\citation{fang2019survey}
\citation{johns2021coarse_to_fine}
\citation{johns2021coarse_to_fine}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Problem Definition}{7}{subsection.1.2.1}\protected@file@percent }
\newlabel{sec:problem_formulation}{{1.2.1}{7}{Problem Definition}{subsection.1.2.1}{}}
\citation{mandlekar2018roboturk}
\citation{mandlekar2019scaling}
\citation{mandlekar2022matters}
\citation{cyberglove}
\citation{touch}
\citation{mandlekar2018roboturk}
\citation{mandlekar2018roboturk}
\citation{smith2019avid}
\citation{sermanet2018time_contrastive}
\citation{liu2019_mirroring_without_overimitation}
\citation{fang2019survey}
\citation{torabi2019recent_advances_lfo}
\citation{liu2017glove_force}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Source of Demonstration}{8}{subsection.1.2.2}\protected@file@percent }
\newlabel{sec:source_of_demonstration}{{1.2.2}{8}{Source of Demonstration}{subsection.1.2.2}{}}
\newlabel{fig:kinesthetic}{{1.4a}{8}{Example of kinesthetic teaching \cite {johns2021coarse_to_fine}\relax }{figure.caption.7}{}}
\newlabel{sub@fig:kinesthetic}{{a}{8}{Example of kinesthetic teaching \cite {johns2021coarse_to_fine}\relax }{figure.caption.7}{}}
\newlabel{fig:teleoperation}{{1.4b}{8}{Example of teleoperation \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.7}{}}
\newlabel{sub@fig:teleoperation}{{b}{8}{Example of teleoperation \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Examples of Direct Demonstration\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:direct_demonstrations}{{1.4}{8}{Examples of Direct Demonstration\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Direct Demonstration}{8}{figure.caption.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Indirect Demonstration}{8}{figure.caption.8}\protected@file@percent }
\BKM@entry{id=7,dest={73756273656374696F6E2E312E322E33},srcline={1}}{5C3337365C3337375C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\citation{osa2018algorithmic}
\citation{ijspeert2002learning}
\citation{ijspeert2013dynamical}
\citation{ijspeert2013dynamical}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces System diagram of Roboturk \cite  {mandlekar2018roboturk}\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:roboturk}{{1.5}{9}{System diagram of Roboturk \cite {mandlekar2018roboturk}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Methods}{9}{subsection.1.2.3}\protected@file@percent }
\newlabel{sec:methods}{{1.2.3}{9}{Methods}{subsection.1.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Behavioral Cloning (BC).}{9}{subsection.1.2.3}\protected@file@percent }
\citation{meier2011movement_primitive}
\citation{caccavale2019kinesthetic}
\citation{agostini2020manipulation}
\citation{paraschos2013ProMPs}
\citation{pomerleau1988alvinn}
\citation{ross2010efficient_reductions}
\citation{ross2011dagger}
\citation{ross2011dagger}
\citation{laskey2017comparing_hc_rc}
\citation{ross2011dagger}
\citation{ross2011dagger}
\citation{kelly2019hg_dagger}
\citation{jang2022bc_z}
\citation{mandlekar2020human_in_the_loop}
\citation{chisari2022correct}
\citation{chisari2022correct}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Abstract Algorithm for Behavioral Cloning\relax }}{10}{algorithm.1}\protected@file@percent }
\newlabel{alg:bc}{{1}{10}{Abstract Algorithm for Behavioral Cloning\relax }{algorithm.1}{}}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{finn2017maml}
\citation{finn2017maml}
\citation{finn2017one_shot_visual_il}
\citation{yu2018daml}
\citation{yu2018one_shot_hil}
\citation{finn2017maml}
\citation{finn2017maml}
\citation{finn2017one_shot_visual_il}
\citation{duan2017one_shot_il}
\citation{duan2017one_shot_il}
\citation{yu2018daml}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces DAgger Algorithm \cite  {ross2011dagger}\relax }}{11}{algorithm.2}\protected@file@percent }
\newlabel{alg:dagger}{{2}{11}{DAgger Algorithm \cite {ross2011dagger}\relax }{algorithm.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Architecture proposed in \cite  {zhang2018deep_vr_teleoperation}\relax }}{12}{figure.caption.9}\protected@file@percent }
\newlabel{fig:deep_bc}{{1.6}{12}{Architecture proposed in \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Statistics of Training set, and Test Success rate \cite  {zhang2018deep_vr_teleoperation}\relax }}{12}{table.caption.10}\protected@file@percent }
\newlabel{table:deep_vr_teleoperation_results}{{1.1}{12}{Statistics of Training set, and Test Success rate \cite {zhang2018deep_vr_teleoperation}\relax }{table.caption.10}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Model-Agnostic Meta-Learning (MAML) \cite  {finn2017maml}\relax }}{12}{algorithm.3}\protected@file@percent }
\newlabel{alg:maml}{{3}{12}{Model-Agnostic Meta-Learning (MAML) \cite {finn2017maml}\relax }{algorithm.3}{}}
\citation{yu2018daml}
\citation{yu2018daml}
\citation{finn2017one_shot_visual_il}
\citation{yu2018daml}
\citation{jang2022bc_z}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{jang2022bc_z}
\citation{kelly2019hg_dagger}
\citation{jang2022bc_z}
\citation{jang2022bc_z}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{yu2018daml}
\citation{dasari2021transformers_one_shot}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{yu2018daml}
\citation{dasari2021transformers_one_shot}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{meier2011movement_primitive}
\citation{caccavale2019kinesthetic}
\citation{agostini2020manipulation}
\citation{caccavale2019kinesthetic}
\citation{xu2018neural_task_programming}
\citation{yang2015robot}
\citation{yu2018one_shot_hil}
\citation{Mandlekar2020GTI}
\citation{yu2018one_shot_hil}
\citation{Mandlekar2020GTI}
\newlabel{eq:daml}{{1.4}{13}{Behavioral Cloning (BC)}{equation.1.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Tasks performed in \cite  {yu2018daml}. (Top row) Human demonstration, (Bottom row) robot demonstration. (Left) Placing task, (Middle) pushing task, (Right) pick-and-place task.\relax }}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig:daml}{{1.7}{13}{Tasks performed in \cite {yu2018daml}. (Top row) Human demonstration, (Bottom row) robot demonstration. (Left) Placing task, (Middle) pushing task, (Right) pick-and-place task.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Architecture proposed in \cite  {jang2022bc_z}\relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{fig:bcz_architecture}{{1.8}{14}{Architecture proposed in \cite {jang2022bc_z}\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Results obtained in single-task and multi-task one-shot imitation learning \cite  {mandi2022towards_more_generalizable_one_shot}.\relax }}{15}{table.caption.13}\protected@file@percent }
\newlabel{table:mosaic}{{1.2}{15}{Results obtained in single-task and multi-task one-shot imitation learning \cite {mandi2022towards_more_generalizable_one_shot}.\relax }{table.caption.13}{}}
\citation{grimes2009learning_actions_through_imitation}
\citation{englert2013probabilistic}
\citation{deisenroth2014multi_task}
\citation{abbeel2004apprenticeship}
\citation{ratliff2006maximum_margin}
\citation{ziebart2008maximum_entropy}
\citation{ratliff2009learning_to_search}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{ratliff2006maximum_margin}
\citation{ratliff2009learning_to_search}
\citation{ziebart2008maximum_entropy}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{ziebart2008maximum_entropy}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{levine2014lqr_flm}
\citation{levine2014lqr_flm}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\@writefile{toc}{\contentsline {paragraph}{Inverse Reinforcement Learning (IRL)}{16}{Item.30}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Classic feature matching IRL algorithm\relax }}{16}{algorithm.4}\protected@file@percent }
\newlabel{alg:irl}{{4}{16}{Classic feature matching IRL algorithm\relax }{algorithm.4}{}}
\newlabel{lqr}{{1.2.3}{17}{Inverse Reinforcement Learning (IRL)}{algorithm.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Guided-Cost-Learning Algorithm \cite  {finn2016guided_cost_learning}\relax }}{17}{algorithm.5}\protected@file@percent }
\newlabel{alg:guided_cost_learning}{{5}{17}{Guided-Cost-Learning Algorithm \cite {finn2016guided_cost_learning}\relax }{algorithm.5}{}}
\citation{ho2016gail}
\citation{ho2016gail}
\citation{ziebart2008maximum_entropy}
\citation{kostrikov2018discriminator}
\citation{fu2018airl}
\citation{ghasemipour2020divergence_minimization_perspective}
\citation{schulman2015trpo}
\citation{brockman2016openai}
\citation{liu2018imitation_from_observation}
\citation{reddy2019sqil}
\citation{zolna2021task_relevant_ail}
\citation{rafailov2021visual_ail}
\citation{zolna2021task_relevant_ail}
\citation{rafailov2021visual_ail}
\citation{zolna2021task_relevant_ail}
\citation{zolna2021task_relevant_ail}
\citation{barth2018d4pg}
\citation{ho2016gail}
\citation{zolna2021task_relevant_ail}
\citation{zolna2021task_relevant_ail}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Architecture proposed in \cite  {das2021model_based_irl_from_vd}\relax }}{18}{figure.caption.14}\protected@file@percent }
\newlabel{fig:model_based_irl}{{1.9}{18}{Architecture proposed in \cite {das2021model_based_irl_from_vd}\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Generative Adversarial Imitation Learning (GAIL)}{18}{figure.caption.14}\protected@file@percent }
\newlabel{para:gail}{{1.2.3}{18}{Generative Adversarial Imitation Learning (GAIL)}{figure.caption.14}{}}
\newlabel{formula:regularized_max_ent}{{1.5}{18}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.5}{}}
\newlabel{formula:policy_characterization}{{1.6}{18}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.6}{}}
\newlabel{formula:ga_regularization}{{1.7}{18}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.7}{}}
\newlabel{formula:ga_regularizer_conjugate}{{1.8}{18}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.8}{}}
\citation{rafailov2021visual_ail}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Generative Adversarial Imitation Learning Algorithm\relax }}{19}{algorithm.6}\protected@file@percent }
\newlabel{alg:gail}{{6}{19}{Generative Adversarial Imitation Learning Algorithm\relax }{algorithm.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Experimental results on tasks without and with spurious features \cite  {zolna2021task_relevant_ail}\relax }}{19}{figure.caption.15}\protected@file@percent }
\newlabel{fig:trail_results}{{1.10}{19}{Experimental results on tasks without and with spurious features \cite {zolna2021task_relevant_ail}\relax }{figure.caption.15}{}}
\citation{reddy2019sqil}
\citation{kostrikov2018discriminator}
\citation{rafailov2021visual_ail}
\citation{rafailov2021visual_ail}
\citation{smith2019avid}
\citation{xiong2021learning_by_watching}
\citation{li2021meta_watching_video_demonstration}
\citation{zakka2022xirl}
\citation{dwibedi2019tcc}
\citation{smith2019avid}
\citation{li2021meta_watching_video_demonstration}
\citation{zhu2017cycle_gan}
\citation{xiong2021learning_by_watching}
\citation{huang2018munit}
\citation{zakka2022xirl}
\citation{zakka2022xirl}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{liu2018imitation_from_observation}
\citation{sermanet2018time_contrastive}
\citation{schroff2015triplet_loss}
\citation{liu2018imitation_from_observation}
\citation{sermanet2018time_contrastive}
\citation{sermanet2018time_contrastive}
\citation{liu2018imitation_from_observation}
\citation{liu2018imitation_from_observation}
\newlabel{formula:elbo}{{1.9}{20}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.9}{}}
\newlabel{formula:discriminator}{{1.10}{20}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.10}{}}
\newlabel{formula:value_function}{{1.11}{20}{Generative Adversarial Imitation Learning (GAIL)}{equation.1.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Control tasks solved in \cite  {rafailov2021visual_ail}. From left to right: cheetah run, walker walk, car racing, claw rotate, baoding balls\relax }}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:vmail}{{1.11}{20}{Control tasks solved in \cite {rafailov2021visual_ail}. From left to right: cheetah run, walker walk, car racing, claw rotate, baoding balls\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Learning from Observation (LfO)}{20}{figure.caption.16}\protected@file@percent }
\newlabel{sec:lfo}{{1.2.3}{20}{Learning from Observation (LfO)}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Representation of embodiment mismatch problem. (Left) The source domain represented by a video of human performing a task. (Right) The target domain, represented by the robot that executes the observed task.\relax }}{21}{figure.caption.17}\protected@file@percent }
\newlabel{fig:embodiment}{{1.12}{21}{Representation of embodiment mismatch problem. (Left) The source domain represented by a video of human performing a task. (Right) The target domain, represented by the robot that executes the observed task.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Temporal-Cycle Consistency representation, used to learn an embodiment-agnostic encoder in \cite  {zakka2022xirl}\relax }}{21}{figure.caption.18}\protected@file@percent }
\newlabel{fig:xirl}{{1.13}{21}{Temporal-Cycle Consistency representation, used to learn an embodiment-agnostic encoder in \cite {zakka2022xirl}\relax }{figure.caption.18}{}}
\citation{sermanet2018time_contrastive}
\citation{xiong2021learning_by_watching}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{sermanet2018time_contrastive}
\citation{xiong2021learning_by_watching}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{merel2017learning}
\citation{torabi2018gaifo}
\citation{merel2017learning}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\citation{ho2016gail}
\citation{brockman2016openai}
\citation{sermanet2018time_contrastive}
\citation{torabi2018bco}
\citation{schulman2015trpo}
\citation{torabi2021dealio}
\citation{chebotar2017pilqr}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\newlabel{fig:time_contrastive}{{1.14a}{22}{Time-Contrastive network, proposed in \cite {sermanet2018time_contrastive}.\relax }{figure.caption.19}{}}
\newlabel{sub@fig:time_contrastive}{{a}{22}{Time-Contrastive network, proposed in \cite {sermanet2018time_contrastive}.\relax }{figure.caption.19}{}}
\newlabel{fig:context-translation}{{1.14b}{22}{Context-Translation network, proposed in \cite {liu2018imitation_from_observation}\relax }{figure.caption.19}{}}
\newlabel{sub@fig:context-translation}{{b}{22}{Context-Translation network, proposed in \cite {liu2018imitation_from_observation}\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Examples of how the mismatch between demonstrator viewpoint and learner viewpoint can be handled.\relax }}{22}{figure.caption.19}\protected@file@percent }
\newlabel{fig:differet_viewpoint}{{1.14}{22}{Examples of how the mismatch between demonstrator viewpoint and learner viewpoint can be handled.\relax }{figure.caption.19}{}}
\citation{nair2017combining}
\citation{torabi2018bco}
\citation{guo2019hybrid_rl}
\citation{radosavovic2021state_only_demo}
\citation{nair2017combining}
\citation{torabi2018bco}
\citation{guo2019hybrid_rl}
\citation{torabi2018bco}
\citation{mnih2016a2c}
\citation{radosavovic2021state_only_demo}
\citation{Rajeswaran18_learning_complex_dexterous}
\citation{Rajeswaran18_learning_complex_dexterous}
\citation{torabi2018bco}
\citation{torabi2018bco}
\citation{smith2019avid}
\citation{torabi2021dealio}
\citation{smith2019avid}
\citation{zhang2019solar}
\citation{Kingma2014_vae}
\citation{levine2014lqr_flm}
\citation{sermanet2018time_contrastive}
\citation{torabi2018bco}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\citation{chebotar2017pilqr}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces GAIfO algorithm \cite  {torabi2018gaifo}\relax }}{23}{algorithm.7}\protected@file@percent }
\newlabel{alg:gaifo_algorithm}{{7}{23}{GAIfO algorithm \cite {torabi2018gaifo}\relax }{algorithm.7}{}}
\newlabel{fig:low_dimensional}{{1.15a}{24}{Experimental results in low-dimensional state space\relax }{figure.caption.20}{}}
\newlabel{sub@fig:low_dimensional}{{a}{24}{Experimental results in low-dimensional state space\relax }{figure.caption.20}{}}
\newlabel{fig:high_dimensional}{{1.15b}{24}{Experimental results in high-dimensional state space\relax }{figure.caption.20}{}}
\newlabel{sub@fig:high_dimensional}{{b}{24}{Experimental results in high-dimensional state space\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Experimental results reported in \cite  {torabi2018gaifo}.\relax }}{24}{figure.caption.20}\protected@file@percent }
\newlabel{fig:gaifo_results}{{1.15}{24}{Experimental results reported in \cite {torabi2018gaifo}.\relax }{figure.caption.20}{}}
\citation{torabi2021dealio}
\citation{torabi2021dealio}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Representation of the learning procedure proposed by \cite  {torabi2018bco}\relax }}{25}{figure.caption.21}\protected@file@percent }
\newlabel{fig:bco}{{1.16}{25}{Representation of the learning procedure proposed by \cite {torabi2018bco}\relax }{figure.caption.21}{}}
\newlabel{formula:linear_gaussian_controller}{{1.12}{25}{Learning from Observation (LfO)}{equation.1.2.12}{}}
\newlabel{formula:quadratic_cost_function}{{1.13}{25}{Learning from Observation (LfO)}{equation.1.2.13}{}}
\newlabel{formula:gaussian_dyn}{{1.14}{25}{Learning from Observation (LfO)}{equation.1.2.14}{}}
\newlabel{formula:output_discriminator}{{1.15}{25}{Learning from Observation (LfO)}{equation.1.2.15}{}}
\BKM@entry{id=8,dest={73756273656374696F6E2E312E322E34},srcline={1}}{5C3337365C3337375C303030535C303030755C3030306D5C3030306D5C303030615C303030725C30303079}
\newlabel{fig:dealio_task}{{1.17a}{26}{Control Tasks solved in \cite {torabi2021dealio}\relax }{figure.caption.22}{}}
\newlabel{sub@fig:dealio_task}{{a}{26}{Control Tasks solved in \cite {torabi2021dealio}\relax }{figure.caption.22}{}}
\newlabel{fig:dealio_performance}{{1.17b}{26}{Performance of DEALIO \cite {torabi2021dealio} compared against GAIfO \cite {torabi2018gaifo}, with respect to the number of trajectories sampled during the learning process.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:dealio_performance}{{b}{26}{Performance of DEALIO \cite {torabi2021dealio} compared against GAIfO \cite {torabi2018gaifo}, with respect to the number of trajectories sampled during the learning process.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces DEAILO: (\ref {fig:dealio_task}) Control Tasks, (\ref {fig:dealio_performance}) Performance Level\relax }}{26}{figure.caption.22}\protected@file@percent }
\newlabel{fig:dealio}{{1.17}{26}{DEAILO: (\ref {fig:dealio_task}) Control Tasks, (\ref {fig:dealio_performance}) Performance Level\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Summary}{26}{subsection.1.2.4}\protected@file@percent }
\newlabel{sec:summary}{{1.2.4}{26}{Summary}{subsection.1.2.4}{}}
\BKM@entry{id=9,dest={636861707465722E32},srcline={1}}{5C3337365C3337375C303030525C303030655C303030735C303030655C303030615C303030725C303030635C303030685C3030305C3034305C303030505C3030306C5C303030615C3030306E}
\BKM@entry{id=10,dest={73656374696F6E2E322E31},srcline={1}}{5C3337365C3337375C303030525C303030655C303030735C303030655C303030615C303030725C303030635C303030685C3030305C3034305C303030675C303030615C303030705C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Research Plan}{28}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:research_plan}{{2}{28}{Research Plan}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Research gaps}{28}{section.2.1}\protected@file@percent }
\newlabel{sec:research_gaps}{{2.1}{28}{Research gaps}{section.2.1}{}}
\BKM@entry{id=11,dest={73656374696F6E2E322E32},srcline={1}}{5C3337365C3337375C303030505C303030725C3030306F5C303030705C3030306F5C303030735C303030655C303030645C3030305C3034305C303030525C303030655C303030735C303030655C303030615C303030725C303030635C303030685C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030695C303030745C30303079}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Proposed Research Activity}{30}{section.2.2}\protected@file@percent }
\newlabel{sec:research_activity}{{2.2}{30}{Proposed Research Activity}{section.2.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Dataset}{31}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Architecture}{31}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{System deployment}{31}{section.2.2}\protected@file@percent }
\BKM@entry{id=12,dest={636861707465722E33},srcline={1}}{5C3337365C3337375C3030304F5C303030745C303030685C303030655C303030725C3030305C3034305C303030415C303030635C303030745C303030695C303030765C303030695C303030745C303030695C303030655C30303073}
\BKM@entry{id=13,dest={73656374696F6E2E332E31},srcline={1}}{5C3337365C3337375C303030415C303030745C303030745C303030655C3030306E5C303030645C303030655C303030645C3030305C3034305C303030435C3030306F5C303030755C303030725C303030735C303030655C30303073}
\BKM@entry{id=14,dest={73756273656374696F6E2E332E312E31},srcline={1}}{5C3337365C3337375C303030435C3030306F5C3030306D5C303030705C303030755C3030306C5C303030735C303030615C303030725C303030795C3030305C3034305C303030635C3030306F5C303030755C303030725C303030735C303030655C30303073}
\BKM@entry{id=15,dest={73756273656374696F6E2E332E312E32},srcline={1}}{5C3337365C3337375C303030415C303030645C303030645C303030695C303030745C303030695C3030306F5C3030306E5C303030615C3030306C5C3030305C3034305C303030635C3030306F5C303030755C303030725C303030735C303030655C30303073}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Other Activities}{32}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:other_activities}{{3}{32}{Other Activities}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Attended Courses}{32}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Compulsary courses}{32}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Additional courses}{32}{subsection.3.1.2}\protected@file@percent }
\bibdata{bibliography.bib}
\bibcite{pepper}{1}
\bibcite{panda}{2}
\bibcite{kalashnikov2018qt_opt}{3}
\bibcite{anne2021meta_learning_fast_adaptive}{4}
\bibcite{jang2022bc_z}{5}
\bibcite{hafner2011reinforcement_in_feedback_controll}{6}
\bibcite{sutton2018reinforcement}{7}
\bibcite{argall2009robot_learning_from_demonstration}{8}
\bibcite{kaelbling1996reinforcement_survey}{9}
\bibcite{osa2018algorithmic}{10}
\bibcite{james2013introduction_to_sl}{11}
\bibcite{cortes1995support}{12}
\bibcite{kullback1951information}{13}
\bibcite{levine202rl_tutorial}{14}
\bibcite{hussein2017imitation_learning_survey}{15}
\bibcite{torabi2019recent_advances_lfo}{16}
\bibcite{codevilla2018end_to_end}{17}
\bibcite{zhang2018deep_vr_teleoperation}{18}
\bibcite{maeda2017probabilistic}{19}
\bibcite{fang2019survey}{20}
\bibcite{kroemer2021review_robot_learning}{21}
\bibcite{johns2021coarse_to_fine}{22}
\bibcite{mandlekar2018roboturk}{23}
\bibcite{mandlekar2019scaling}{24}
\bibcite{mandlekar2022matters}{25}
\bibcite{cyberglove}{26}
\bibcite{touch}{27}
\bibcite{smith2019avid}{28}
\bibcite{sermanet2018time_contrastive}{29}
\bibcite{liu2019_mirroring_without_overimitation}{30}
\bibcite{liu2017glove_force}{31}
\bibcite{ijspeert2002learning}{32}
\bibcite{ijspeert2013dynamical}{33}
\bibcite{meier2011movement_primitive}{34}
\bibcite{caccavale2019kinesthetic}{35}
\bibcite{agostini2020manipulation}{36}
\bibcite{paraschos2013ProMPs}{37}
\bibcite{pomerleau1988alvinn}{38}
\bibcite{ross2010efficient_reductions}{39}
\bibcite{ross2011dagger}{40}
\bibcite{laskey2017comparing_hc_rc}{41}
\bibcite{kelly2019hg_dagger}{42}
\bibcite{mandlekar2020human_in_the_loop}{43}
\bibcite{chisari2022correct}{44}
\bibcite{finn2017maml}{45}
\bibcite{finn2017one_shot_visual_il}{46}
\bibcite{yu2018daml}{47}
\bibcite{yu2018one_shot_hil}{48}
\bibcite{duan2017one_shot_il}{49}
\bibcite{mandi2022towards_more_generalizable_one_shot}{50}
\bibcite{dasari2021transformers_one_shot}{51}
\bibcite{xu2018neural_task_programming}{52}
\bibcite{yang2015robot}{53}
\bibcite{Mandlekar2020GTI}{54}
\bibcite{grimes2009learning_actions_through_imitation}{55}
\bibcite{englert2013probabilistic}{56}
\bibcite{deisenroth2014multi_task}{57}
\bibcite{abbeel2004apprenticeship}{58}
\bibcite{ratliff2006maximum_margin}{59}
\bibcite{ziebart2008maximum_entropy}{60}
\bibcite{ratliff2009learning_to_search}{61}
\bibcite{wulfmeier2015deep_inverse_rl}{62}
\bibcite{finn2016guided_cost_learning}{63}
\bibcite{levine2014lqr_flm}{64}
\bibcite{das2021model_based_irl_from_vd}{65}
\bibcite{ho2016gail}{66}
\bibcite{kostrikov2018discriminator}{67}
\bibcite{fu2018airl}{68}
\bibcite{ghasemipour2020divergence_minimization_perspective}{69}
\bibcite{schulman2015trpo}{70}
\bibcite{brockman2016openai}{71}
\bibcite{liu2018imitation_from_observation}{72}
\bibcite{reddy2019sqil}{73}
\bibcite{zolna2021task_relevant_ail}{74}
\bibcite{rafailov2021visual_ail}{75}
\bibcite{barth2018d4pg}{76}
\bibcite{xiong2021learning_by_watching}{77}
\bibcite{li2021meta_watching_video_demonstration}{78}
\bibcite{zakka2022xirl}{79}
\bibcite{dwibedi2019tcc}{80}
\bibcite{zhu2017cycle_gan}{81}
\bibcite{huang2018munit}{82}
\bibcite{schroff2015triplet_loss}{83}
\bibcite{merel2017learning}{84}
\bibcite{torabi2018gaifo}{85}
\bibcite{torabi2018bco}{86}
\bibcite{torabi2021dealio}{87}
\bibcite{chebotar2017pilqr}{88}
\bibcite{nair2017combining}{89}
\bibcite{guo2019hybrid_rl}{90}
\bibcite{radosavovic2021state_only_demo}{91}
\bibcite{mnih2016a2c}{92}
\bibcite{Rajeswaran18_learning_complex_dexterous}{93}
\bibcite{zhang2019solar}{94}
\bibcite{Kingma2014_vae}{95}
\BKM@entry{id=16,dest={636861707465722A2E3233},srcline={128}}{5C3337365C3337375C303030425C303030695C303030625C3030306C5C303030695C3030306F5C303030675C303030725C303030615C303030705C303030685C30303079}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{41}{chapter*.23}\protected@file@percent }
\gdef \@abspage@last{42}
