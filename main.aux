\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\bibstyle{ieeetr}
\babel@aux{english}{}
\newlabel{chapter:overview}{{}{1}{Overview}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{Overview}{1}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Background}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{2}{section.1.1}\protected@file@percent }
\newlabel{sec:intro}{{1.1}{2}{Introduction}{section.1.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:welding}{{1.1a}{2}{Robots involved in arc welding operation\relax }{figure.caption.3}{}}
\newlabel{sub@fig:welding}{{a}{2}{Robots involved in arc welding operation\relax }{figure.caption.3}{}}
\newlabel{fig:material_handling}{{1.1b}{2}{Robot involved in loading operation\relax }{figure.caption.3}{}}
\newlabel{sub@fig:material_handling}{{b}{2}{Robot involved in loading operation\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Industrial Robots: example of applications\relax }}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:industrial_robots_example}{{1.1}{2}{Industrial Robots: example of applications\relax }{figure.caption.3}{}}
\citation{pepper}
\citation{panda}
\citation{kalashnikov2018qt_opt}
\citation{anne2021meta_learning_fast_adaptive}
\citation{jang2022bc_z}
\citation{hafner2011reinforcement_in_feedback_controll}
\citation{sutton2018reinforcement}
\citation{argall2009robot_learning_from_demonstration}
\citation{kaelbling1996reinforcement_survey}
\citation{}
\citation{osa2018algorithmic}
\citation{james2013introduction_to_sl}
\citation{cortes1995support}
\citation{kullback1951information}
\citation{levine202rl_tutorial}
\citation{}
\citation{}
\citation{levine202rl_tutorial}
\citation{levine202rl_tutorial}
\citation{hussein2017imitation_learning_survey}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{torabi2019recent_advances_lfo}
\citation{}
\citation{}
\citation{}
\citation{codevilla2018end_to_end}
\citation{zhang2018deep_vr_teleoperation}
\citation{maeda2017probabilistic}
\newlabel{fig:onpolicy}{{1.2a}{4}{On-policy RL\relax }{figure.caption.4}{}}
\newlabel{sub@fig:onpolicy}{{a}{4}{On-policy RL\relax }{figure.caption.4}{}}
\newlabel{fig:offpolicy}{{1.2b}{4}{Off-policy RL\relax }{figure.caption.4}{}}
\newlabel{sub@fig:offpolicy}{{b}{4}{Off-policy RL\relax }{figure.caption.4}{}}
\newlabel{fig:offline}{{1.2c}{4}{Offline RL\relax }{figure.caption.4}{}}
\newlabel{sub@fig:offline}{{c}{4}{Offline RL\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Graphical Representation of Reinforcement Learning Methods \cite  {levine202rl_tutorial}\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:rl_methods}{{1.2}{4}{Graphical Representation of Reinforcement Learning Methods \cite {levine202rl_tutorial}\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Imitation Learning: Taxonomy and main components\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:il_methods}{{1.3}{5}{Imitation Learning: Taxonomy and main components\relax }{figure.caption.5}{}}
\citation{fang2019survey}
\citation{osa2018algorithmic}
\citation{}
\citation{}
\citation{}
\citation{kroemer2021review_robot_learning}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}State-of-the-Art (last page 27)}{6}{section.1.2}\protected@file@percent }
\newlabel{sec:sota}{{1.2}{6}{State-of-the-Art (last page 27)}{section.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Problem Definition}{6}{subsection.1.2.1}\protected@file@percent }
\newlabel{sec:problem_formulation}{{1.2.1}{6}{Problem Definition}{subsection.1.2.1}{}}
\citation{fang2019survey}
\citation{johns2021coarse_to_fine}
\citation{johns2021coarse_to_fine}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{mandlekar2018roboturk}
\citation{mandlekar2019scaling}
\citation{mandlekar2022matters}
\citation{cyberglove}
\citation{touch}
\citation{mandlekar2018roboturk}
\citation{mandlekar2018roboturk}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Source of Demonstration [MAX 5]}{7}{subsection.1.2.2}\protected@file@percent }
\newlabel{sec:source_of_demonstration}{{1.2.2}{7}{Source of Demonstration [MAX 5]}{subsection.1.2.2}{}}
\newlabel{fig:kinesthetic}{{1.4a}{7}{Example of kinesthetic teaching \cite {johns2021coarse_to_fine}\relax }{figure.caption.6}{}}
\newlabel{sub@fig:kinesthetic}{{a}{7}{Example of kinesthetic teaching \cite {johns2021coarse_to_fine}\relax }{figure.caption.6}{}}
\newlabel{fig:teleoperation}{{1.4b}{7}{Example of teleoperation \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.6}{}}
\newlabel{sub@fig:teleoperation}{{b}{7}{Example of teleoperation \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Examples of Direct Demonstration\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:direct_demonstrations}{{1.4}{7}{Examples of Direct Demonstration\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Direct Demonstration}{7}{figure.caption.6}\protected@file@percent }
\citation{smith2019avid}
\citation{sermanet2018time_contrastive}
\citation{liu2019_mirroring_without_overimitation}
\citation{fang2019survey}
\citation{torabi2019recent_advances_lfo}
\citation{liu2017glove_force}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces System diagram of Roboturk \cite  {mandlekar2018roboturk}\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:roboturk}{{1.5}{8}{System diagram of Roboturk \cite {mandlekar2018roboturk}\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Indirect Demonstration}{8}{figure.caption.7}\protected@file@percent }
\citation{osa2018algorithmic}
\citation{ijspeert2002learning}
\citation{ijspeert2013dynamical}
\citation{ijspeert2013dynamical}
\citation{caccavale2019kinesthetic}
\citation{eiband2019learning}
\citation{agostini2020manipulation}
\citation{paraschos2013ProMPs}
\citation{pomerleau1988alvinn}
\citation{ross2010efficient_reductions}
\citation{ross2011dagger}
\citation{ross2011dagger}
\citation{laskey2017comparing_hc_rc}
\citation{ross2011dagger}
\citation{ross2011dagger}
\citation{kelly2019hg_dagger}
\citation{jang2022bc_z}
\citation{mandlekar2020human_in_the_loop}
\citation{chisari2022correct}
\citation{chisari2022correct}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Methods}{9}{subsection.1.2.3}\protected@file@percent }
\newlabel{sec:methods}{{1.2.3}{9}{Methods}{subsection.1.2.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Behavioral Cloning (BC). [MAX 5]}{9}{subsection.1.2.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Abstract Algorithm for Behavioral Cloning\relax }}{9}{algorithm.1}\protected@file@percent }
\newlabel{alg:bc}{{1}{9}{Abstract Algorithm for Behavioral Cloning\relax }{algorithm.1}{}}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{zhang2018deep_vr_teleoperation}
\citation{finn2017maml}
\citation{finn2017maml}
\citation{finn2017one_shot_visual_il}
\citation{yu2018daml}
\citation{yu2018one_shot_hil}
\citation{finn2017maml}
\citation{finn2017maml}
\citation{finn2017one_shot_visual_il}
\citation{duan2017one_shot_il}
\citation{duan2017one_shot_il}
\citation{yu2018daml}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces DAgger Algorithm \cite  {ross2011dagger}\relax }}{11}{algorithm.2}\protected@file@percent }
\newlabel{alg:dagger}{{2}{11}{DAgger Algorithm \cite {ross2011dagger}\relax }{algorithm.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Architecture proposed in \cite  {zhang2018deep_vr_teleoperation}\relax }}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:deep_bc}{{1.6}{11}{Architecture proposed in \cite {zhang2018deep_vr_teleoperation}\relax }{figure.caption.8}{}}
\citation{yu2018one_shot_hil}
\citation{yu2018daml}
\citation{yu2018daml}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Statistics of Training set, and Test Success rate \cite  {zhang2018deep_vr_teleoperation}\relax }}{12}{table.caption.9}\protected@file@percent }
\newlabel{table:deep_vr_teleoperation_results}{{1.1}{12}{Statistics of Training set, and Test Success rate \cite {zhang2018deep_vr_teleoperation}\relax }{table.caption.9}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Model-Agnostic Meta-Learning (MAML) \cite  {finn2017maml}\relax }}{12}{algorithm.3}\protected@file@percent }
\newlabel{alg:maml}{{3}{12}{Model-Agnostic Meta-Learning (MAML) \cite {finn2017maml}\relax }{algorithm.3}{}}
\newlabel{eq:daml}{{1.4}{12}{Behavioral Cloning (BC). [MAX 5]}{equation.1.2.4}{}}
\citation{finn2017one_shot_visual_il}
\citation{yu2018daml}
\citation{jang2022bc_z}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{jang2022bc_z}
\citation{ross2011dagger}
\citation{jang2022bc_z}
\citation{jang2022bc_z}
\citation{mandi2022towards_more_generalizable_one_shot}
\citation{yu2018daml}
\citation{dasari2021transformers_one_shot}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Tasks performed in \cite  {yu2018daml}. (Top row) Human demonstration, (Bottom row) robot demonstration. (Left) Placing task, (Middle) pushing task, (Right) pick-and-place task.\relax }}{13}{figure.caption.10}\protected@file@percent }
\newlabel{fig:daml}{{1.7}{13}{Tasks performed in \cite {yu2018daml}. (Top row) Human demonstration, (Bottom row) robot demonstration. (Left) Placing task, (Middle) pushing task, (Right) pick-and-place task.\relax }{figure.caption.10}{}}
\citation{grimes2009learning_actions_through_imitation}
\citation{englert2013probabilistic}
\citation{deisenroth2014multi_task}
\citation{abbeel2004apprenticeship}
\citation{ratliff2006maximum_margin}
\citation{ziebart2008maximum_entropy}
\citation{ratliff2009learning_to_search}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{ratliff2006maximum_margin}
\citation{ratliff2009learning_to_search}
\citation{ziebart2008maximum_entropy}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{ziebart2008maximum_entropy}
\citation{wulfmeier2015deep_inverse_rl}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{finn2016guided_cost_learning}
\citation{levine2014lqr_flm}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\citation{das2021model_based_irl_from_vd}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Architecture proposed in \cite  {jang2022bc_z}\relax }}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig:bcz_architecture}{{1.8}{14}{Architecture proposed in \cite {jang2022bc_z}\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Inverse Reinforcement Learning (IRL) [MAX 2]}{14}{Item.25}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Classic feature matching IRL algorithm\relax }}{15}{algorithm.4}\protected@file@percent }
\newlabel{alg:irl}{{4}{15}{Classic feature matching IRL algorithm\relax }{algorithm.4}{}}
\citation{ho2016gail}
\citation{ho2016gail}
\newlabel{lqr}{{1.2.3}{16}{Inverse Reinforcement Learning (IRL) [MAX 2]}{algorithm.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Guided-Cost-Learning Algorithm \cite  {finn2016guided_cost_learning}\relax }}{16}{algorithm.5}\protected@file@percent }
\newlabel{alg:guided_cost_learning}{{5}{16}{Guided-Cost-Learning Algorithm \cite {finn2016guided_cost_learning}\relax }{algorithm.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{16}{figure.caption.12}\protected@file@percent }
\newlabel{para:gail}{{1.2.3}{16}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{figure.caption.12}{}}
\citation{ziebart2008maximum_entropy}
\citation{kostrikov2018discriminator}
\citation{fu2018airl}
\citation{ghasemipour2020divergence_minimization_perspective}
\citation{schulman2015trpo}
\citation{brockman2016openai}
\citation{liu2018imitation_from_observation}
\citation{reddy2019sqil}
\citation{zolna2021task_relevant_ail}
\citation{rafailov2021visual_ail}
\citation{zolna2021task_relevant_ail}
\citation{rafailov2021visual_ail}
\citation{zolna2021task_relevant_ail}
\citation{zolna2021task_relevant_ail}
\citation{barth2018d4pg}
\citation{ho2016gail}
\citation{zolna2021task_relevant_ail}
\citation{zolna2021task_relevant_ail}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Architecture proposed in \cite  {das2021model_based_irl_from_vd}\relax }}{17}{figure.caption.12}\protected@file@percent }
\newlabel{fig:model_based_irl}{{1.9}{17}{Architecture proposed in \cite {das2021model_based_irl_from_vd}\relax }{figure.caption.12}{}}
\newlabel{formula:regularized_max_ent}{{1.5}{17}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.5}{}}
\newlabel{formula:policy_characterization}{{1.6}{17}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.6}{}}
\newlabel{formula:ga_regularization}{{1.7}{17}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.7}{}}
\newlabel{formula:ga_regularizer_conjugate}{{1.8}{17}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.8}{}}
\citation{zolna2021task_relevant_ail}
\citation{zolna2021task_relevant_ail}
\citation{rafailov2021visual_ail}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Generative Adversarial Imitation Learning Algorithm\relax }}{18}{algorithm.6}\protected@file@percent }
\newlabel{alg:gail}{{6}{18}{Generative Adversarial Imitation Learning Algorithm\relax }{algorithm.6}{}}
\newlabel{fig:block_lifting}{{1.10a}{18}{Block lifting\relax }{figure.caption.13}{}}
\newlabel{sub@fig:block_lifting}{{a}{18}{Block lifting\relax }{figure.caption.13}{}}
\newlabel{fig:block_lifting_with_distractors}{{1.10b}{18}{Block lifting with distractors\relax }{figure.caption.13}{}}
\newlabel{sub@fig:block_lifting_with_distractors}{{b}{18}{Block lifting with distractors\relax }{figure.caption.13}{}}
\newlabel{fig:block_stacking}{{1.10c}{18}{Block stacking\relax }{figure.caption.13}{}}
\newlabel{sub@fig:block_stacking}{{c}{18}{Block stacking\relax }{figure.caption.13}{}}
\newlabel{fig:bloc_insertion_with_distractors}{{1.10d}{18}{Block insertion with distractors\relax }{figure.caption.13}{}}
\newlabel{sub@fig:bloc_insertion_with_distractors}{{d}{18}{Block insertion with distractors\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Tasks solved in \cite  {zolna2021task_relevant_ail}\relax }}{18}{figure.caption.13}\protected@file@percent }
\newlabel{fig:trail}{{1.10}{18}{Tasks solved in \cite {zolna2021task_relevant_ail}\relax }{figure.caption.13}{}}
\citation{reddy2019sqil}
\citation{kostrikov2018discriminator}
\citation{rafailov2021visual_ail}
\citation{rafailov2021visual_ail}
\newlabel{fig:trail_results_without_spurious}{{1.11a}{19}{Experimental results on tasks without spurious features\relax }{figure.caption.14}{}}
\newlabel{sub@fig:trail_results_without_spurious}{{a}{19}{Experimental results on tasks without spurious features\relax }{figure.caption.14}{}}
\newlabel{fig:trail_results_with_spurious}{{1.11b}{19}{Experimental results on task with spurious features\relax }{figure.caption.14}{}}
\newlabel{sub@fig:trail_results_with_spurious}{{b}{19}{Experimental results on task with spurious features\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Experimental results in \cite  {zolna2021task_relevant_ail}\relax }}{19}{figure.caption.14}\protected@file@percent }
\newlabel{fig:trail_results}{{1.11}{19}{Experimental results in \cite {zolna2021task_relevant_ail}\relax }{figure.caption.14}{}}
\newlabel{formula:elbo}{{1.9}{19}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.9}{}}
\newlabel{formula:discriminator}{{1.10}{19}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.10}{}}
\newlabel{formula:value_function}{{1.11}{19}{Generative Adversarial Imitation Learning (GAIL) [MAX 5]}{equation.1.2.11}{}}
\citation{smith2019avid}
\citation{xiong2021learning_by_watching}
\citation{li2021meta_watching_video_demonstration}
\citation{zakka2022xirl}
\citation{dwibedi2019tcc}
\citation{smith2019avid}
\citation{li2021meta_watching_video_demonstration}
\citation{zhu2017cycle_gan}
\citation{xiong2021learning_by_watching}
\citation{huang2018munit}
\citation{zakka2022xirl}
\citation{zakka2022xirl}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{liu2018imitation_from_observation}
\citation{sermanet2018time_contrastive}
\citation{schroff2015triplet_loss}
\citation{liu2018imitation_from_observation}
\citation{liu2018imitation_from_observation}
\citation{liu2018imitation_from_observation}
\citation{sermanet2018time_contrastive}
\citation{sermanet2018time_contrastive}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Control tasks solved in \cite  {rafailov2021visual_ail}. From left to right: cheetah run, walker walk, car racing, claw rotate, baoding balls\relax }}{20}{figure.caption.15}\protected@file@percent }
\newlabel{fig:vmail}{{1.12}{20}{Control tasks solved in \cite {rafailov2021visual_ail}. From left to right: cheetah run, walker walk, car racing, claw rotate, baoding balls\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {paragraph}{Learning from Observation (LfO) [MAX 5]}{20}{figure.caption.15}\protected@file@percent }
\newlabel{sec:lfo}{{1.2.3}{20}{Learning from Observation (LfO) [MAX 5]}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Representation of embodiment mismatch problem. (Left) The source domain represented by a video of human performing a task. (Right) The target domain, represented by the robot that executes the observed task.\relax }}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:embodiment}{{1.13}{20}{Representation of embodiment mismatch problem. (Left) The source domain represented by a video of human performing a task. (Right) The target domain, represented by the robot that executes the observed task.\relax }{figure.caption.16}{}}
\citation{sermanet2018time_contrastive}
\citation{xiong2021learning_by_watching}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{sermanet2018time_contrastive}
\citation{xiong2021learning_by_watching}
\citation{zakka2022xirl}
\citation{sermanet2018time_contrastive}
\citation{merel2017learning}
\citation{torabi2018gaifo}
\citation{merel2017learning}
\citation{ho2016gail}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\citation{ho2016gail}
\citation{brockman2016openai}
\citation{sermanet2018time_contrastive}
\citation{torabi2018bco}
\citation{schulman2015trpo}
\citation{torabi2021dealio}
\citation{chebotar2017pilqr}
\citation{torabi2018gaifo}
\citation{torabi2018gaifo}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Temporal-Cycle Consistency representation, used to learn an embodiment-agnostic encoder in \cite  {zakka2022xirl}\relax }}{21}{figure.caption.17}\protected@file@percent }
\newlabel{fig:xirl}{{1.14}{21}{Temporal-Cycle Consistency representation, used to learn an embodiment-agnostic encoder in \cite {zakka2022xirl}\relax }{figure.caption.17}{}}
\newlabel{fig:context-translation}{{1.15a}{22}{Context-Translation network, proposed in \cite {liu2018imitation_from_observation}\relax }{figure.caption.18}{}}
\newlabel{sub@fig:context-translation}{{a}{22}{Context-Translation network, proposed in \cite {liu2018imitation_from_observation}\relax }{figure.caption.18}{}}
\newlabel{fig:time_contrastive}{{1.15b}{22}{Time-Contrastive network, proposed in \cite {sermanet2018time_contrastive}.\relax }{figure.caption.18}{}}
\newlabel{sub@fig:time_contrastive}{{b}{22}{Time-Contrastive network, proposed in \cite {sermanet2018time_contrastive}.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Examples of how the mismatch between demonstrator viewpoint and learner viewpoint can be handled.\relax }}{22}{figure.caption.18}\protected@file@percent }
\newlabel{fig:differet_viewpoint}{{1.15}{22}{Examples of how the mismatch between demonstrator viewpoint and learner viewpoint can be handled.\relax }{figure.caption.18}{}}
\citation{nair2017combining}
\citation{torabi2018bco}
\citation{guo2019hybrid_rl}
\citation{radosavovic2021state_only_demo}
\citation{nair2017combining}
\citation{torabi2018bco}
\citation{guo2019hybrid_rl}
\citation{torabi2018bco}
\citation{mnih2016a2c}
\citation{radosavovic2021state_only_demo}
\citation{Rajeswaran18_learning_complex_dexterous}
\citation{Rajeswaran18_learning_complex_dexterous}
\citation{torabi2018bco}
\citation{torabi2018bco}
\citation{smith2019avid}
\citation{torabi2021dealio}
\citation{smith2019avid}
\citation{zhang2019solar}
\citation{Kingma2014_vae}
\citation{levine2014lqr_flm}
\citation{sermanet2018time_contrastive}
\citation{torabi2018bco}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\citation{chebotar2017pilqr}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces GAIfO algorithm \cite  {torabi2018gaifo}\relax }}{23}{algorithm.7}\protected@file@percent }
\newlabel{alg:gaifo_algorithm}{{7}{23}{GAIfO algorithm \cite {torabi2018gaifo}\relax }{algorithm.7}{}}
\newlabel{fig:low_dimensional}{{1.16a}{24}{Experimental results in low-dimensional state space\relax }{figure.caption.19}{}}
\newlabel{sub@fig:low_dimensional}{{a}{24}{Experimental results in low-dimensional state space\relax }{figure.caption.19}{}}
\newlabel{fig:high_dimensional}{{1.16b}{24}{Experimental results in high-dimensional state space\relax }{figure.caption.19}{}}
\newlabel{sub@fig:high_dimensional}{{b}{24}{Experimental results in high-dimensional state space\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Experimental results reported in \cite  {torabi2018gaifo}.\relax }}{24}{figure.caption.19}\protected@file@percent }
\newlabel{fig:gaifo_results}{{1.16}{24}{Experimental results reported in \cite {torabi2018gaifo}.\relax }{figure.caption.19}{}}
\citation{torabi2021dealio}
\citation{torabi2021dealio}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\citation{torabi2021dealio}
\citation{torabi2018gaifo}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces Representation of the learning procedure proposed by \cite  {torabi2018bco}\relax }}{25}{figure.caption.20}\protected@file@percent }
\newlabel{fig:bco}{{1.17}{25}{Representation of the learning procedure proposed by \cite {torabi2018bco}\relax }{figure.caption.20}{}}
\newlabel{formula:output_discriminator}{{1.12}{25}{Learning from Observation (LfO) [MAX 5]}{equation.1.2.12}{}}
\newlabel{fig:dealio_task}{{1.18a}{26}{Control Tasks solved in \cite {torabi2021dealio}\relax }{figure.caption.21}{}}
\newlabel{sub@fig:dealio_task}{{a}{26}{Control Tasks solved in \cite {torabi2021dealio}\relax }{figure.caption.21}{}}
\newlabel{fig:dealio_performance}{{1.18b}{26}{Performance of DEALIO \cite {torabi2021dealio} compared against GAIfO \cite {torabi2018gaifo}, with respect to the number of trajectories sampled during the learning process.\relax }{figure.caption.21}{}}
\newlabel{sub@fig:dealio_performance}{{b}{26}{Performance of DEALIO \cite {torabi2021dealio} compared against GAIfO \cite {torabi2018gaifo}, with respect to the number of trajectories sampled during the learning process.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.18}{\ignorespaces DEAILO: (\ref {fig:dealio_task}) Control Tasks, (\ref {fig:dealio_performance}) Performance Level\relax }}{26}{figure.caption.21}\protected@file@percent }
\newlabel{fig:dealio}{{1.18}{26}{DEAILO: (\ref {fig:dealio_task}) Control Tasks, (\ref {fig:dealio_performance}) Performance Level\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Summary}{26}{subsection.1.2.4}\protected@file@percent }
\newlabel{sec:summary}{{1.2.4}{26}{Summary}{subsection.1.2.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Research Plan}{27}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Other Activities}{28}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Attended Courses}{28}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Compulsary courses}{28}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Additional courses}{28}{subsection.3.1.2}\protected@file@percent }
\bibdata{bibliography.bib}
\bibcite{pepper}{1}
\bibcite{panda}{2}
\bibcite{kalashnikov2018qt_opt}{3}
\bibcite{anne2021meta_learning_fast_adaptive}{4}
\bibcite{jang2022bc_z}{5}
\bibcite{hafner2011reinforcement_in_feedback_controll}{6}
\bibcite{sutton2018reinforcement}{7}
\bibcite{argall2009robot_learning_from_demonstration}{8}
\bibcite{kaelbling1996reinforcement_survey}{9}
\bibcite{osa2018algorithmic}{10}
\bibcite{james2013introduction_to_sl}{11}
\bibcite{cortes1995support}{12}
\bibcite{kullback1951information}{13}
\bibcite{levine202rl_tutorial}{14}
\bibcite{hussein2017imitation_learning_survey}{15}
\bibcite{torabi2019recent_advances_lfo}{16}
\bibcite{codevilla2018end_to_end}{17}
\bibcite{zhang2018deep_vr_teleoperation}{18}
\bibcite{maeda2017probabilistic}{19}
\bibcite{fang2019survey}{20}
\bibcite{kroemer2021review_robot_learning}{21}
\bibcite{johns2021coarse_to_fine}{22}
\bibcite{mandlekar2018roboturk}{23}
\bibcite{mandlekar2019scaling}{24}
\bibcite{mandlekar2022matters}{25}
\bibcite{cyberglove}{26}
\bibcite{touch}{27}
\bibcite{smith2019avid}{28}
\bibcite{sermanet2018time_contrastive}{29}
\bibcite{liu2019_mirroring_without_overimitation}{30}
\bibcite{liu2017glove_force}{31}
\bibcite{zheng2021imitation_progress_taxonomies_opportunities}{32}
\bibcite{ijspeert2002learning}{33}
\bibcite{ijspeert2013dynamical}{34}
\bibcite{caccavale2019kinesthetic}{35}
\bibcite{eiband2019learning}{36}
\bibcite{agostini2020manipulation}{37}
\bibcite{paraschos2013ProMPs}{38}
\bibcite{pomerleau1988alvinn}{39}
\bibcite{ross2010efficient_reductions}{40}
\bibcite{ross2011dagger}{41}
\bibcite{laskey2017comparing_hc_rc}{42}
\bibcite{kelly2019hg_dagger}{43}
\bibcite{mandlekar2020human_in_the_loop}{44}
\bibcite{chisari2022correct}{45}
\bibcite{finn2017maml}{46}
\bibcite{finn2017one_shot_visual_il}{47}
\bibcite{yu2018daml}{48}
\bibcite{yu2018one_shot_hil}{49}
\bibcite{duan2017one_shot_il}{50}
\bibcite{mandi2022towards_more_generalizable_one_shot}{51}
\bibcite{dasari2021transformers_one_shot}{52}
\bibcite{grimes2009learning_actions_through_imitation}{53}
\bibcite{englert2013probabilistic}{54}
\bibcite{deisenroth2014multi_task}{55}
\bibcite{abbeel2004apprenticeship}{56}
\bibcite{ratliff2006maximum_margin}{57}
\bibcite{ziebart2008maximum_entropy}{58}
\bibcite{ratliff2009learning_to_search}{59}
\bibcite{wulfmeier2015deep_inverse_rl}{60}
\bibcite{finn2016guided_cost_learning}{61}
\bibcite{levine2014lqr_flm}{62}
\bibcite{das2021model_based_irl_from_vd}{63}
\bibcite{ho2016gail}{64}
\bibcite{kostrikov2018discriminator}{65}
\bibcite{fu2018airl}{66}
\bibcite{ghasemipour2020divergence_minimization_perspective}{67}
\bibcite{schulman2015trpo}{68}
\bibcite{brockman2016openai}{69}
\bibcite{liu2018imitation_from_observation}{70}
\bibcite{reddy2019sqil}{71}
\bibcite{zolna2021task_relevant_ail}{72}
\bibcite{rafailov2021visual_ail}{73}
\bibcite{barth2018d4pg}{74}
\bibcite{xiong2021learning_by_watching}{75}
\bibcite{li2021meta_watching_video_demonstration}{76}
\bibcite{zakka2022xirl}{77}
\bibcite{dwibedi2019tcc}{78}
\bibcite{zhu2017cycle_gan}{79}
\bibcite{huang2018munit}{80}
\bibcite{schroff2015triplet_loss}{81}
\bibcite{merel2017learning}{82}
\bibcite{torabi2018gaifo}{83}
\bibcite{torabi2018bco}{84}
\bibcite{torabi2021dealio}{85}
\bibcite{chebotar2017pilqr}{86}
\bibcite{nair2017combining}{87}
\bibcite{guo2019hybrid_rl}{88}
\bibcite{radosavovic2021state_only_demo}{89}
\bibcite{mnih2016a2c}{90}
\bibcite{Rajeswaran18_learning_complex_dexterous}{91}
\bibcite{zhang2019solar}{92}
\bibcite{Kingma2014_vae}{93}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{37}{chapter*.22}\protected@file@percent }
\gdef \@abspage@last{38}
